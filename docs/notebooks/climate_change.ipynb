{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Climate change analysis of hydrological data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Hide INFO-level logs\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import hvplot.xarray\n",
    "import numpy as np\n",
    "import pooch\n",
    "import xarray as xr\n",
    "import xclim\n",
    "\n",
    "import xhydro as xh\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "# This notebook will use data from the 2022 edition of the Hydrological Atlas of Southern Quebec, which can be accessed from the xhydro-testdata repository.\n",
    "# They cover 2 stations: ABIT00057 and ABIT00058\n",
    "GITHUB_URL = \"https://github.com/hydrologie/xhydro-testdata\"\n",
    "BRANCH_OR_COMMIT_HASH = \"main\"\n",
    "\n",
    "# Streamflow file (1 file - Hydrotel driven by BCC-CSM-1.1(m))\n",
    "streamflow_file = pooch.retrieve(\n",
    "    url=f\"{GITHUB_URL}/raw/{BRANCH_OR_COMMIT_HASH}/data/cc_indicators/streamflow_BCC-CSM1.1-m_rcp45.nc\",\n",
    "    known_hash=\"md5:0ac83a4ee9dceecda68ac1ee542f50de\",\n",
    ")\n",
    "\n",
    "# Reference QMOYAN (6 platforms)\n",
    "ref_zip = pooch.retrieve(\n",
    "    url=f\"{GITHUB_URL}/raw/{BRANCH_OR_COMMIT_HASH}/data/cc_indicators/reference.zip\",\n",
    "    known_hash=\"md5:192544f3a081375a81d423e08038d32a\",\n",
    ")\n",
    "directory_to_extract_to = Path(ref_zip).parent\n",
    "with ZipFile(ref_zip, \"r\") as ziploc:\n",
    "    ziploc.extractall(directory_to_extract_to)\n",
    "    files = ziploc.namelist()\n",
    "reference_files = [directory_to_extract_to / f for f in files]\n",
    "\n",
    "# QMOYAN deltas (63 simulations x 6 platforms)\n",
    "deltas_zip = pooch.retrieve(\n",
    "    url=f\"{GITHUB_URL}/raw/{BRANCH_OR_COMMIT_HASH}/data/cc_indicators/deltas.zip\",\n",
    "    known_hash=\"md5:ce6371e073e5324f9ade385c1c03e7eb\",\n",
    ")\n",
    "directory_to_extract_to = Path(deltas_zip).parent\n",
    "with ZipFile(deltas_zip, \"r\") as ziploc:\n",
    "    ziploc.extractall(directory_to_extract_to)\n",
    "    files = ziploc.namelist()\n",
    "deltas_files = [directory_to_extract_to / f for f in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "While there is a huge variety of analyses that could be done to assess the impacts of climate change on hydrology, this notebook will go through some of the most common steps:\n",
    "\n",
    "- Computing a list of relevant indicators over climatological periods\n",
    "- Computing future deltas\n",
    "- Computing ensemble statistics to assess future changes\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>INFO</b>\n",
    "\n",
    "Multiple functions in `xh.indicators` and `xh.cc` have been leveraged from the `xscen` library and made accessible to `xhydro` users. For more information on these function, it is recommended to look at:\n",
    "\n",
    "- [compute_indicators](https://xscen.readthedocs.io/en/latest/notebooks/2_getting_started.html#Computing-indicators)\n",
    "- [climatological_op](https://xscen.readthedocs.io/en/latest/notebooks/2_getting_started.html#Climatological-operations)\n",
    "- [compute_deltas](https://xscen.readthedocs.io/en/latest/notebooks/2_getting_started.html#Computing-deltas)\n",
    "- [ensemble_statistics](https://xscen.readthedocs.io/en/latest/notebooks/2_getting_started.html#Ensemble-statistics)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Computing hydrological indicators over a given time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file used as an example is a daily timeseries of streamflow data generated from the Hydrotel hydrological model\n",
    "# driven by bias-adjusted data from the BCC-CSM-1.1(m) climatological model (RCP4.5), from 1950 to 2100.\n",
    "# For this example, the dataset covers only 2 stations.\n",
    "ds = xr.open_dataset(streamflow_file)\n",
    "ds.streamflow.hvplot(x=\"time\", grid=True, widget_location=\"bottom\", groupby=\"station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Hydrological indicators can be separated in two broad categories: \n",
    "\n",
    "- Frequential indicators, such as the maximum 20-year flow (*Qmax20*) or the minimum 2-year 7-day averaged flow in summer (*Q7min2_summer*). Computing these is already covered in the [Local Frequency Analysis notebook](local_frequency_analysis.ipynb) notebook.\n",
    "- Non frequencial indicators, such as the average yearly flow.\n",
    "\n",
    "Since frequential indicators have already been covered in another example, this notebook will instead look at the methodology that would be used to compute non frequential indicators using `xhydro.indicators.compute_indicators`. The inputs of that function are:\n",
    "\n",
    "- *ds*: the Dataset.\n",
    "- *indicators*: a list of indicators to compute, or the path to a YAML file containing those.\n",
    "- *periods* (optional): either [start, end] or list of [start, end] of continuous periods over which to compute the indicators.\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>INFO</b>\n",
    "\n",
    "Custom indicators are built by following the YAML formatting required by `xclim`. More information is available [in the xclim documentation](https://xclim.readthedocs.io/en/latest/api.html#yaml-file-structure).\n",
    "\n",
    "The list of Yaml IDs is available [here](https://xclim.readthedocs.io/en/stable/indicators.html).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll define 2 indicators to compute by using dictionaries.\n",
    "#\n",
    "# We minimally need to define three things under `data`:\n",
    "#    1. 'base': A base indicator for the computation, identified through its Yaml ID (here, 'stats').\n",
    "#    2. 'parameters': Specific parameters to use instead of the defaults.\n",
    "#      - This potentially includes a 'indexer' parameter to focus on particular periods of the year.\n",
    "#    3. 'input': The name of the input variable. The key here must be the variable name used by xclim (here, 'da').\n",
    "#\n",
    "# The 'identifier' is the label that will be given by 'xclim' to the new indicator. The 'module' can be anything.\n",
    "\n",
    "indicators = [\n",
    "    # 1st indicator: Mean annual flow\n",
    "    xclim.core.indicator.Indicator.from_dict(\n",
    "        data={\n",
    "            \"base\": \"stats\",\n",
    "            \"input\": {\"da\": \"streamflow\"},\n",
    "            \"parameters\": {\"op\": \"mean\"},\n",
    "        },\n",
    "        identifier=\"QMOYAN\",\n",
    "        module=\"hydro\",\n",
    "    ),\n",
    "    # 2nd indicator: Mean summer-fall flow\n",
    "    xclim.core.indicator.Indicator.from_dict(\n",
    "        data={\n",
    "            \"base\": \"stats\",\n",
    "            \"input\": {\"da\": \"streamflow\"},\n",
    "            \"parameters\": {\"op\": \"mean\", \"indexer\": {\"month\": [6, 7, 8, 9, 10, 11]}},\n",
    "        },  # The indexer is used to restrict available data to the relevant months only\n",
    "        identifier=\"QMOYEA\",\n",
    "        module=\"hydro\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Call compute_indicators\n",
    "dict_indicators = xh.indicators.compute_indicators(ds, indicators=indicators)\n",
    "\n",
    "dict_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_indicators[\"YS-JAN\"].QMOYAN.hvplot(\n",
    "    x=\"time\", grid=True, widget_location=\"bottom\", groupby=\"station\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Since indicators could be output at varying frequencies, `compute_indicators` will return a dictionary where the keys are the output frequencies. In this example, we only have one key: `AS-JAN` (annual data starting in January). The keys follow the `pandas` nomenclature.\n",
    "\n",
    "The next step is to obtain averages over climatological periods. The `xh.cc.climatological_op` function can be called for this purpose. The inputs of that function are:\n",
    "    \n",
    "- *ds*: Dataset to use for the computation.\n",
    "- *op*: Operation to perform over time. While other operations are technically possible, the following are recommended and tested:  ['max', 'mean', 'median', 'min', 'std', 'sum', 'var', 'linregress'].\n",
    "- *window* (optional): Number of years to use for the rolling operation. If None, all the available data will be used.\n",
    "- *min_periods* (optional): For the rolling operation, minimum number of years required for a value to be computed.\n",
    "- *stride*: Stride (in years) at which to provide an output from the rolling window operation.\n",
    "- *periods* (optional): Either [start, end] or list of [start, end] of continuous periods to be considered.\n",
    "- *rename_variables*: If True, '_clim_{op}' will be added to variable names.\n",
    "- *horizons_as_dim*: If True, the output will have 'horizon' and the frequency as 'month', 'season' or 'year' as dimensions and coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the periods using a list of lists\n",
    "periods = [[1981, 2010], [2011, 2040], [2041, 2070], [2071, 2100]]\n",
    "min_periods = 29  # This is an example of a model where the data stops in 2099, so we can use 'min_periods' to still obtain a value for the last period\n",
    "\n",
    "# Call climatological_op. Here we don't need 'time' anymore, so we can use horizons_as_dim=True\n",
    "ds_avg = xh.cc.climatological_op(\n",
    "    dict_indicators[\"YS-JAN\"],\n",
    "    op=\"mean\",\n",
    "    periods=periods,\n",
    "    min_periods=min_periods,\n",
    "    horizons_as_dim=True,\n",
    "    rename_variables=False,\n",
    ").drop_vars([\"time\"])\n",
    "ds_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Computing deltas is then as easy as calling `xh.cc.compute_deltas`. The inputs of that function are:\n",
    "    \n",
    "- *ds*: Dataset to use for the computation.\n",
    "- *reference_horizon*: Either a YYYY-YYYY string corresponding to the 'horizon' coordinate of the reference period, or a xr.Dataset containing the climatological mean.\n",
    "- *kind*: ['+', '/', '%'] Whether to provide absolute, relative, or percentage deltas. Can also be a dictionary separated per variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we'll use a string from the 'horizon' dimension.\n",
    "reference_horizon = \"1981-2010\"\n",
    "kind = \"%\"\n",
    "\n",
    "ds_deltas = xh.cc.compute_deltas(\n",
    "    ds_avg, reference_horizon=reference_horizon, kind=kind, rename_variables=False\n",
    ")\n",
    "ds_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results as Dataframes\n",
    "print(\"30-year averages\")\n",
    "display(ds_avg.QMOYAN.isel(station=0).to_dataframe())\n",
    "print(\"Deltas\")\n",
    "display(ds_deltas.QMOYAN.isel(station=0).to_dataframe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Ensemble statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save time, let's open pre-computed deltas for the RCP4.5 simulations used in the 2022 Hydroclimatic Atlas\n",
    "ds_dict_deltas = {}\n",
    "for f in deltas_files:\n",
    "    id = Path(f).stem\n",
    "    ds_dict_deltas[id] = xr.open_dataset(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "It is a good practice to use multiple climate models to perform climate change analyses, especially since the impacts on the hydrological cycle can be non linear. Once multiple hydrological simulations have been run and are ready to be analysed, `xh.cc.ensemble_stats` can be used to call a variety of functions available in `xclim.ensemble`, such as for getting ensemble quantiles or the agreement on the sign of the change.\n",
    "\n",
    "### Weighting simulations\n",
    "If the ensemble of climate models is heterogeneous, for example if a given climate model has provided more simulations, it is recommended to weight the results accordingly. While this is not currently available through `xhydro`, `xscen.generate_weights` can create a first approximation of the weights to use, based on available metadata.\n",
    "\n",
    "The following attributes are required for the function to work:\n",
    "\n",
    "- 'cat:source' in all datasets\n",
    "- 'cat:driving_model' in regional climate models\n",
    "- 'cat:institution' in all datasets if independence_level='institution'\n",
    "- 'cat:experiment' in all datasets if split_experiments=True\n",
    "\n",
    "That function has three possible independence levels:\n",
    "\n",
    "- *model*: 1 Model - 1 Vote\n",
    "- *GCM*: 1 GCM - 1 Vote\n",
    "- *institution*: 1 institution - 1 Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xscen\n",
    "\n",
    "independence_level = \"model\"  # 1 Model - 1 Vote\n",
    "\n",
    "weights = xscen.generate_weights(ds_dict_deltas, independence_level=independence_level)\n",
    "\n",
    "# Show the results. We multiply by 6 for the showcase here simply because there are 6 hydrological platforms in the results.\n",
    "weights.where(weights.realization.str.contains(\"LN24HA\"), drop=True) * 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Use Case #1: Deterministic reference data\n",
    "\n",
    "In most cases, you'll likely have deterministic data for the reference period, meaning that for a given location, the 30-year average for the indicator is a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Hydrological Portrait produces probabilistic estimates, but we'll take the 50th percentile to fake deterministic data\n",
    "ref = xr.open_dataset(reference_files[0]).sel(percentile=50).drop_vars(\"percentile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Multiple methodologies exist on how to combine the information of the observed and simulated data. Due to biases that may remain in the climate simulations even after bias adjustment and affect the hydrological modelling, we'll use a perturbation technique. This is especially relevant in hydrology with regards to non linear interactions between the climate and hydrological indicators.\n",
    "\n",
    "The perturbation technique consists in computing ensemble percentiles on the deltas, then apply them on the reference dataset.For this example, we'll compute the 10th, 25th, 50th, 75th, and 90th percentiles of the ensemble, as well as the agreement on the sign of change, using `xh.cc.ensemble_stats`. The inputs of that function are:\n",
    "\n",
    "- *datasets*: List of file paths or xarray Dataset/DataArray objects to include in the ensemble. A dictionary can be passed instead of a list, in which case the keys are used as coordinates along the new `realization` axis.\n",
    "- *statistics*:  dictionary of xclim.ensembles statistics to be called, with their arguments.\n",
    "- *weights* (optional):  Weights to apply along the 'realization' dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics to compute\n",
    "statistics = {\n",
    "    \"ensemble_percentiles\": {\"values\": [10, 25, 50, 75, 90], \"split\": False},\n",
    "    \"robustness_fractions\": {\"test\": None},\n",
    "}  # Robustness fractions is the function that provides the agreement between models.\n",
    "\n",
    "# Here, we call ensemble_stats on the dictionary deltas, since this is the information that we want to extrapolate.\n",
    "# If relevant, weights are added at this step\n",
    "ens_stats = xh.cc.ensemble_stats(ds_dict_deltas, statistics, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional statistics not explicitly supported by ensemble_stats\n",
    "from xclim.ensembles import robustness_categories\n",
    "\n",
    "# Interquartile range\n",
    "ens_stats[\"QMOYAN_iqr\"] = ens_stats[\"QMOYAN\"].sel(percentiles=75) - ens_stats[\n",
    "    \"QMOYAN\"\n",
    "].sel(percentiles=25)\n",
    "\n",
    "# Categories of agreement for the sign of change. This follows the Advanced IPCC Atlas categories.\n",
    "# See the Cross-Chapter Box 1 for reference: https://www.cambridge.org/core/books/climate-change-2021-the-physical-science-basis/atlas/24E1C016DBBE4725BDFBC343695DE7DB\n",
    "# For thresholds and ops, the first entry is related to the significance test, while the 2nd is related to the percentage of simulations that see a positive delta.\n",
    "# For example, \"Agreement towards increase\" is met if more than 66% of simulations see a significant change AND 80% of simulations see a positive change.\n",
    "categories = [\n",
    "    \"Agreement towards increase\",\n",
    "    \"Agreement towards decrease\",\n",
    "    \"Conflicting signals\",\n",
    "    \"No change or robust signal\",\n",
    "]\n",
    "thresholds = [[0.66, 0.8], [0.66, 0.2], [0.66, 0.8], [0.66, np.nan]]\n",
    "ops = [[\">=\", \">=\"], [\">=\", \"<=\"], [\">=\", \"<\"], [\"<\", None]]\n",
    "\n",
    "ens_stats[\"QMOYAN_robustness_categories\"] = robustness_categories(\n",
    "    changed_or_fractions=ens_stats[\"QMOYAN_changed\"],\n",
    "    agree=ens_stats[\"QMOYAN_positive\"],\n",
    "    categories=categories,\n",
    "    thresholds=thresholds,\n",
    "    ops=ops,\n",
    ")\n",
    "\n",
    "# The future values for QMOYAN can be obtained by multiplying the reference indicator with the percentiles of the ensemble deltas\n",
    "ens_stats[\"QMOYAN_projected\"] = ref.QMOYAN * (1 + ens_stats.QMOYAN / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Use Case #2: Probabilistic reference data\n",
    "\n",
    "This method follows a similar approach to Use Case #1, but for a case like the [Hydrological Atlas of Southern Quebec](https://cehq.gouv.qc.ca/atlas-hydroclimatique/), where the hydrological indicators computed for the historical period are represented by a probability density function (PDF), rather than a discrete value. This means that the ensemble percentiles can't simply be multiplied by the reference value.\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>INFO</b>\n",
    "\n",
    "Note that the percentiles in `ref` are <b>not</b> the interannual variability, but rather the uncertainty related, for example, to hydrological modelling or the quality of the input data. At this stage, the temporal average should already have been done.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = xr.open_mfdataset(reference_files, combine=\"nested\", concat_dim=\"platform\")\n",
    "\n",
    "# Rather than a single value, QMOYAN is represented by 21 percentiles that try to represent the uncertainty surrounding this statistics.\n",
    "# Like for the future simulations, we also have 6 hydrological platforms to take into account.\n",
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can also be represented as a cumulative distribution function (CDF)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for platform in ref.platform:\n",
    "    plt.plot(\n",
    "        ref.QMOYAN.isel(station=0).sel(platform=platform),\n",
    "        ref.QMOYAN.percentile / 100,\n",
    "        \"grey\",\n",
    "    )\n",
    "    plt.xlabel(\"Mean annual flow (m³/s)\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.title(\"CDF for QMOYAN @ ABIT00057 \\nEach line is an hydrological platform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Because of their probabilistic nature, the historical reference values can't easily be combined to the future deltas. The `sampled_indicators` function has been created to circumvent this issue. That function will:\n",
    "\n",
    "1. Sample 'n' values from the historical distribution, weighting the percentiles by their associated coverage.\n",
    "2. Sample 'n' values from the delta distribution, using the provided weights.\n",
    "3. Create the future distribution by applying the sampled deltas to the sampled historical distribution, element-wise.\n",
    "4. Compute the percentiles of the future distribution.\n",
    "\n",
    "The inputs of that function are:\n",
    "\n",
    "- *ds*: Dataset containing the historical indicators. The indicators are expected to be represented by a distribution of pre-computed percentiles.\n",
    "- *deltas*: Dataset containing the future deltas to apply to the historical indicators.\n",
    "- *delta_type*: Type of delta provided. Must be one of ['absolute', 'percentage'].\n",
    "- *ds_weights* (optional): Weights to use when sampling the historical indicators, for dimensions other than 'percentile'/'quantile'. Dimensions not present in this Dataset, or if None, will be sampled uniformly unless they are shared with 'deltas'.\n",
    "- *delta_weights* (optional): Weights to use when sampling the deltas, such as along the 'realization' dimension. Dimensions not present in this Dataset, or if None, will be sampled uniformly unless they are shared with 'ds'.\n",
    "- *n*: Number of samples to generate.\n",
    "- *seed* (optional): Seed to use for the random number generator.\n",
    "- *return_dist*: Whether to return the full distributions (ds, deltas, fut) or only the percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 300000\n",
    "deltas = xclim.ensembles.create_ensemble(\n",
    "    ds_dict_deltas\n",
    ")  # The function expects an xarray object. This xclim function can be used to easily create the required input.\n",
    "\n",
    "# Compute the perturbed indicators\n",
    "fut_pct, hist_dist, delta_dist, fut_dist = xh.cc.sampled_indicators(\n",
    "    ref,\n",
    "    deltas=deltas,\n",
    "    delta_type=\"percentage\",\n",
    "    delta_weights=weights,\n",
    "    n=n,\n",
    "    seed=0,\n",
    "    return_dist=True,\n",
    ")\n",
    "\n",
    "fut_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's show how the historical distribution was sampled and reconstructed\n",
    "\n",
    "\n",
    "def _make_cdf(ds, bins):\n",
    "    count, bins_count = np.histogram(ds.QMOYAN.isel(station=0), bins=bins)\n",
    "    pdf = count / sum(count)\n",
    "    return bins_count, np.cumsum(pdf)\n",
    "\n",
    "\n",
    "# Barplot\n",
    "plt.subplot(2, 1, 1)\n",
    "uniquen = np.unique(hist_dist.QMOYAN.isel(station=0), return_counts=True)\n",
    "plt.bar(uniquen[0], uniquen[1], width=0.01, color=\"k\")\n",
    "plt.ylabel(\"Number of instances\")\n",
    "plt.title(\"Sampling within the historical distribution\")\n",
    "\n",
    "# CDF\n",
    "plt.subplot(2, 1, 2)\n",
    "for i, platform in enumerate(ref.platform):\n",
    "    plt.plot(\n",
    "        ref.QMOYAN.isel(station=0).sel(platform=platform),\n",
    "        ref.percentile / 100,\n",
    "        \"grey\",\n",
    "        label=\"CDFs from the percentiles\" if i == 0 else None,\n",
    "    )\n",
    "bc, c = _make_cdf(hist_dist, bins=50)\n",
    "plt.plot(bc[1:], c, \"r\", label=f\"Sampled historical CDF (n={n})\", linewidth=3)\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlabel(\"QMOYAN (m³/s)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, let's show how the deltas were sampled, for the last horizon\n",
    "\n",
    "# Plot #3\n",
    "plt.subplot(2, 1, 1)\n",
    "uniquen = np.unique(delta_dist.QMOYAN.isel(station=0, horizon=-1), return_counts=True)\n",
    "plt.bar(uniquen[0], uniquen[1], width=0.25, color=\"k\")\n",
    "plt.ylabel(\"Number of instances\")\n",
    "plt.title(\"Sampling within the historical distribution\")\n",
    "\n",
    "# Plot #2\n",
    "plt.subplot(2, 1, 2)\n",
    "bc, c = _make_cdf(delta_dist, bins=100)\n",
    "plt.plot(bc[1:], c, \"k\", label=f\"Sampled deltas CDF (n={n})\", linewidth=3)\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlabel(\"Deltas (%)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distributions can be used to quickly create boxplots\n",
    "plt.boxplot(\n",
    "    [\n",
    "        hist_dist.QMOYAN.isel(station=0),\n",
    "        fut_dist.QMOYAN.isel(station=0, horizon=0),\n",
    "        fut_dist.QMOYAN.isel(station=0, horizon=1),\n",
    "        fut_dist.QMOYAN.isel(station=0, horizon=2),\n",
    "    ],\n",
    "    labels=[\"Historical\", \"2011-2040\", \"2041-2070\", \"2071-2100\"],\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Mean summer flow (m³/s)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same statistics as before can also be computed by using delta_dist\n",
    "delta_dist = delta_dist.rename({\"sample\": \"realization\"})  # xclim compatibility\n",
    "ens_stats_2 = xh.cc.ensemble_stats(delta_dist, statistics)\n",
    "\n",
    "# Interquartile range\n",
    "ens_stats_2[\"QMOYAN_iqr\"] = ens_stats_2[\"QMOYAN\"].sel(percentiles=75) - ens_stats_2[\n",
    "    \"QMOYAN\"\n",
    "].sel(percentiles=25)\n",
    "\n",
    "# Categories of agreement on the sign of change\n",
    "ens_stats_2[\"QMOYAN_robustness_categories\"] = robustness_categories(\n",
    "    changed_or_fractions=ens_stats_2[\"QMOYAN_changed\"],\n",
    "    agree=ens_stats_2[\"QMOYAN_positive\"],\n",
    "    categories=categories,\n",
    "    thresholds=thresholds,\n",
    "    ops=ops,\n",
    ")\n",
    "\n",
    "ens_stats_2"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
