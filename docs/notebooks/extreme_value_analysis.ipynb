{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Value Analysis using Extremes.jl\n",
    "\n",
    "This module provides an easy-to-use wrapper for the `Extremes.jl` Julia package, enabling seamless integration with `xarray` for extreme value analysis. However, do note that `juliacall` is not installed by default when installing `xHydro`. Consult the installation page for instructions.\n",
    "\n",
    "The `Extremes.jl` package is specifically designed for analyzing extreme values and offers a variety of powerful features:\n",
    "\n",
    "- Block Maxima and Threshold Exceedance methods, including popular distributions such as `genextreme`, `gumbel_r`, and `genpareto`.\n",
    "- Flexible parameter estimation techniques, supporting methods like `Probability-Weighted Moments (PWM)`, `Maximum Likelihood Estimation (MLE)`, and `Bayesian Estimation`.\n",
    "- Compatibility with both stationary and non-stationary models for flexible modeling of future extreme events.\n",
    "- Return level estimation for quantifying the risk of extreme events over different return periods.\n",
    "\n",
    "For further information on the `Extremes.jl` package, consult the following resources:\n",
    "- [Extremes.jl - JSS Article](https://doi.org/10.18637/jss.v109.i06)\n",
    "- [Extremes.jl GitHub Repository](https://github.com/jojal5/Extremes.jl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T20:54:27.904824Z",
     "start_time": "2024-12-11T20:54:10.703052Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTHON_JULIACALL_AUTOLOAD_IPYTHON_EXTENSION\"] = (\n",
    "    \"no\"  # To prevent random crashes with GitHub's testing interface\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pooch\n",
    "\n",
    "import xhydro.extreme_value_analysis as xhe\n",
    "from xhydro.testing.helpers import deveraux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition\n",
    "\n",
    "This example will use climate data from the `GFDL-ESM4.1` model to demonstrate non-stationarity. The dataset includes annual total precipitation data from 1955 to 2100, spanning 97 virtual stations across the province of Quebec. For more information on how to access precipitation data or perform block maxima, consult the [Local frequency analyses](local_frequency_analysis.ipynb) notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T20:54:28.052959Z",
     "start_time": "2024-12-11T20:54:27.909829Z"
    }
   },
   "outputs": [],
   "source": [
    "file = deveraux().fetch(\"extreme_value_analysis/NOAA_GFDL_ESM4.zip\", pooch.Unzip())\n",
    "\n",
    "df = pd.read_csv(file[0], parse_dates=[0])[\n",
    "    [\"time\", \"station_num\", \"station_name\", \"total_precip\"]\n",
    "]\n",
    "# That dataset is a CSV file, so we need to format it\n",
    "ds = df.to_xarray()\n",
    "ds = ds.set_coords([\"time\", \"station_num\", \"station_name\"])\n",
    "ds = ds.set_index(index=[\"station_num\", \"time\"])\n",
    "ds = ds.unstack(\"index\")\n",
    "ds[\"total_precip\"].attrs[\"units\"] = \"mm y-1\"\n",
    "\n",
    "# Take a subset for the example\n",
    "ds = ds.isel(station_num=slice(0, 5))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T20:54:28.202587Z",
     "start_time": "2024-12-11T20:54:28.105446Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[7, 3])\n",
    "ds.isel(station_num=0).total_precip.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><b>WARNING</b>\n",
    "    \n",
    "Currently, there is no way to provide `Extremes.jl` with a predefined set of parameters to directly calculate return levels. Until this functionality is implemented in either `xHydro` or `Extremes.jl`, the `.fit()` and `.return_level()` functions should be considered independent. Specifically, the `.return_level()` function will first estimate the distribution parameters before calculating the return levels.\n",
    "    \n",
    "</div>\n",
    "\n",
    "## Parameter estimation\n",
    "\n",
    "The `xhydro.extreme_value_analysis.fit` function serves as the interface between `xHydro` and the `Extremes.jl` package. Most of the arguments mirror those used in the `xhydro.frequency_analysis.local.fit` function. The statistical distribution names have been made to align with those in `SciPy`. Below are a few key differences:\n",
    "\n",
    "- Bayesian Method (`BAYES`): When using the `BAYES` method, you can specify two additional parameters:\n",
    "  - `niter`: Number of iterations for the Bayesian inference algorithm.\n",
    "  - `warmup`: Number of warmup iterations for the Bayesian inference.\n",
    "- Confidence Intervals:  A significant addition to this function is the `confidence_level` parameter, which simplifies the process of obtaining confidence interval compared to the other options available in `xHydro`, as detailed in the other frequency analysis notebooks.\n",
    "\n",
    "In this example, we will estimate a Generalized Extreme Value (GEV) distribution (`genextreme`) using the Probability Weighted Moments (`PWM`) method. Additionally, we will calculate and return the 95% confidence intervals for the estimated parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(xhe.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T20:54:35.121255Z",
     "start_time": "2024-12-11T20:54:28.257188Z"
    }
   },
   "outputs": [],
   "source": [
    "fit_stationary = xhe.fit(\n",
    "    ds,\n",
    "    dist=\"genextreme\",\n",
    "    method=\"PWM\",\n",
    "    variables=[\"total_precip\"],\n",
    "    confidence_level=0.95,\n",
    ")\n",
    "fit_stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return levels\n",
    "\n",
    "As mentioned in the warning above, the `xhydro.extreme_value_analysis.return_level` function cannot accept pre-defined parameters and `Extremes.jl` must compute them internally. Therefore, with the inclusion of the `return_period` argument, all function parameters remain the same.\n",
    "\n",
    "In this example, we will estimate a Gumbel distribution (`gumbel_r`) using the Maximum Likelihood (`ML`) method. Additionally, we will calculate and return the 95% confidence intervals for the estimated parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(xhe.return_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T20:54:37.882475Z",
     "start_time": "2024-12-11T20:54:35.133335Z"
    }
   },
   "outputs": [],
   "source": [
    "rtnlv_stationary = xhe.return_level(\n",
    "    ds,\n",
    "    dist=\"gumbel_r\",\n",
    "    method=\"ML\",\n",
    "    variables=[\"total_precip\"],\n",
    "    confidence_level=0.95,\n",
    "    return_period=100,\n",
    ")\n",
    "rtnlv_stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-stationary model\n",
    "\n",
    "So far, we've skipped three additional arguments—`locationcov`, `scalecov`, and `shapecov`—that accept variable names. These arguments allow you to introduce a non-linear aspect to the statistical model. In non-stationary models, explanatory variables (covariates) can be used to capture changes in model parameters over time or across different conditions. These covariates can represent factors such as time, geographic location, global temperature increases or CO2 concentrations, or any other variable that may influence the distribution parameters.\n",
    "\n",
    "Also, note that the `PWM` method cannot be used with non-stationary models.\n",
    "\n",
    "For this example, we'll keep it simple and assume that the location parameter varies as a linear function of the year. To do this, we'll need to add a new variable containing the year to our dataset and then provide this variable to the `locationcov` argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T20:54:37.928189Z",
     "start_time": "2024-12-11T20:54:37.909414Z"
    }
   },
   "outputs": [],
   "source": [
    "ds[\"year\"] = ds.time.dt.year.broadcast_like(ds[\"total_precip\"])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the `.fit()` function, adding a covariate will introduce a new entry under the `dparams` dimension. For this example, it created a new entry called `loc_year_covariate` under the `dparams` dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T20:54:40.472181Z",
     "start_time": "2024-12-11T20:54:37.945894Z"
    }
   },
   "outputs": [],
   "source": [
    "fit_non_stationary = xhe.fit(\n",
    "    ds,\n",
    "    dist=\"genextreme\",\n",
    "    method=\"ML\",\n",
    "    variables=[\"total_precip\"],\n",
    "    locationcov=[\"year\"],\n",
    "    confidence_level=0.95,\n",
    ")\n",
    "fit_non_stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the `.return_level()` function, adding a covariate will expand the `return_level` dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T20:54:42.950294Z",
     "start_time": "2024-12-11T20:54:40.489891Z"
    }
   },
   "outputs": [],
   "source": [
    "rtnlv_non_stationary = xhe.return_level(\n",
    "    ds,\n",
    "    dist=\"gumbel_r\",\n",
    "    method=\"ML\",\n",
    "    variables=[\"total_precip\"],\n",
    "    locationcov=[\"year\"],\n",
    "    confidence_level=0.95,\n",
    "    return_period=100,\n",
    ")\n",
    "\n",
    "rtnlv_non_stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of the return level using the stationary and non-stationary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(6)\n",
    "\n",
    "# Stationary fit\n",
    "plt.plot(\n",
    "    np.array([1, 1]),\n",
    "    np.array(\n",
    "        [\n",
    "            rtnlv_stationary.total_precip_lower.isel(station_num=0),\n",
    "            rtnlv_stationary.total_precip_upper.isel(station_num=0),\n",
    "        ]\n",
    "    ),\n",
    "    \"black\",\n",
    "    label=\"Stationary\",\n",
    ")\n",
    "plt.scatter(\n",
    "    np.array([1]),\n",
    "    np.array([rtnlv_stationary.total_precip.isel(station_num=0)]),\n",
    "    c=\"black\",\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    np.array([2, 2]),\n",
    "    np.array(\n",
    "        [\n",
    "            rtnlv_non_stationary.total_precip_lower.isel(station_num=0, return_level=0),\n",
    "            rtnlv_non_stationary.total_precip_upper.isel(station_num=0, return_level=0),\n",
    "        ]\n",
    "    ),\n",
    "    \"red\",\n",
    "    label=\"Non-Stationary (1955)\",\n",
    ")\n",
    "plt.scatter(\n",
    "    np.array([2]),\n",
    "    np.array([rtnlv_non_stationary.total_precip.isel(station_num=0, return_level=0)]),\n",
    "    c=\"red\",\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    np.array([3, 3]),\n",
    "    np.array(\n",
    "        [\n",
    "            rtnlv_non_stationary.total_precip_lower.isel(\n",
    "                station_num=0, return_level=-1\n",
    "            ),\n",
    "            rtnlv_non_stationary.total_precip_upper.isel(\n",
    "                station_num=0, return_level=-1\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    \"green\",\n",
    "    label=\"Non-Stationary (2100)\",\n",
    ")\n",
    "plt.scatter(\n",
    "    np.array([3]),\n",
    "    np.array([rtnlv_non_stationary.total_precip.isel(station_num=0, return_level=-1)]),\n",
    "    c=\"green\",\n",
    ")\n",
    "\n",
    "plt.xlim([0, 4])\n",
    "plt.xticks([])\n",
    "plt.ylabel(\"Total precipitation (mm)\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with `dask.array` Chunks\n",
    "\n",
    "Currently, the Python-to-Julia interaction is not thread-safe. To mitigate potential issues, it is recommended to use the `dask.scheduler=\"processes\"` option when computing results. This ensures that tasks are executed in separate Python processes, providing better isolation and avoiding thread-related conflicts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T20:54:43.238969Z",
     "start_time": "2024-12-11T20:54:43.188645Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_c = ds.chunk({\"time\": -1, \"station_num\": 1})\n",
    "\n",
    "fit_stationary_c = xhe.fit(\n",
    "    ds_c,\n",
    "    dist=\"genextreme\",\n",
    "    method=\"ml\",\n",
    "    variables=[\"total_precip\"],\n",
    "    confidence_level=0.95,\n",
    ")\n",
    "fit_stationary_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T20:55:15.279290Z",
     "start_time": "2024-12-11T20:54:43.263523Z"
    }
   },
   "outputs": [],
   "source": [
    "fit_stationary_c.compute(scheduler=\"processes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
