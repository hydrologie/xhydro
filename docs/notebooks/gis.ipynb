{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIS module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GIS operations are integral to hydrology processes. This page demonstrates how to use `xhydro` to perform GIS manipulations such as delineating watershed boundaries and extracting physiographic, climatological and geographical variables at the watershed scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import leafmap\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xclim\n",
    "import xdatasets as xd\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "import xhydro.gis as xhgis\n",
    "from xhydro.indicators import get_yearly_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watershed delineation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, watershed delineation uses HydroBASINS (hybas_na_lev01-12_v1c) and can work in any location in North America. The process involves assessing all upstream sub-basins from a specified outlet and consolidating them into a unified watershed. The [leafmap](https://leafmap.org/) library is employed for generating interactive maps. This map serves the purpose of selecting outlets or visualizing the resulting watershed boundaries. Although utilizing the map is not essential for conducting the calculations, it proves useful for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = leafmap.Map(center=(48.63, -74.71), zoom=5, basemap=\"USGS Hydrography\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) From a list of coordinates\n",
    "In this scenario, we select two pour points, with each one representing the outlet for the watersheds of Lac Saint-Jean and the Ottawa River, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lng_lat = [\n",
    "    (-69.81971, 48.14720),  # Lac Saint-Jean watershed\n",
    "    (-74.393438, 45.572442),  # Ottawa river watershed\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) From markers on a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using a list, a more interactive approach is to directly select outlets from the existing map ``m``. The following image illustrates the process of selecting pour points by dragging markers to the desired locations on the map.\n",
    "\n",
    "![test](../../docs/_static/_images/example_draw_marker.png)\n",
    "\n",
    "The next cell is only useful for the documentation as it simulates a user selecting an outlet from the map `m`. You should instead remove this code and interact with the map in object `m` as shown above by positionning markers at sites of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.draw_features = [\n",
    "    {\n",
    "        \"type\": \"Feature\",\n",
    "        \"properties\": {},\n",
    "        \"geometry\": {\"type\": \"Point\", \"coordinates\": [-73.118597, 46.042467]},\n",
    "    }\n",
    "]  # Richelieu watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selecting points using either approach a) or b), or a combination of both, we can initiate the watershed delineation calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = xhgis.watershed_delineation(coordinates=lng_lat, map=m)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcomes are stored in a GeoPandas `gpd.GeoDataFrame` (`gdf`) object, allowing us to save our polygons in various common formats such as an ESRI Shapefile or GeoJSON. If a map ``m`` is present, the polygons will automatically be added to it. If you want to visualize the map, simply type ``m`` in the code cell to render it. If displaying the map directly is not compatible with your notebook interpreter, you can utilize the following code to extract the HTML from the map and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.zoom_to_gdf(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) From [xdatasets](https://github.com/hydrologie/xdatasets)\n",
    "\n",
    "Automatically delineating watershed boundaries is a valuable tool in the toolbox, but users are encouraged to utilize official watershed boundaries if they already exist, instead of creating new ones. This functionality fetches a list of basins from [xdatasets](https://github.com/hydrologie/xdatasets) supported datasets, and upon request, [xdatasets](https://github.com/hydrologie/xdatasets) provides a `gpd.GeoDataFrame` containing the precalculated boundaries for these basins. Currently, the following watershed sources are available as of today.:\n",
    "\n",
    "| Source                                                                                                                                                             | Dataset name   |\n",
    "|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------|\n",
    "| [DEH](https://www.cehq.gouv.qc.ca/atlas-hydroclimatique/stations-hydrometriques/index.htm)                                                                         | deh_polygons   |\n",
    "| [HYDAT](https://www.canada.ca/en/environment-climate-change/services/water-overview/quantity/monitoring/survey/data-products-services/national-archive-hydat.html) | hydat_polygons |\n",
    "| [HQ](https://www.hydroquebec.com/r)                                                                                                                                | hq_polygons    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = xd.Query(\n",
    "    **{\n",
    "        \"datasets\": {\n",
    "            \"deh_polygons\": {\n",
    "                \"id\": [\"031*\", \"0421*\"],\n",
    "                \"regulated\": [\"Natural\"],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ").data.reset_index()\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract watershed properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining our watershed boundaries, we can extract valuable properties such as geographical information, land use classification and climatological data from the delineated watersheds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Geographical watershed properties\n",
    "Initially, we extract geographical properties of the watershed, including the perimeter, total area, Gravelius coefficient and basin centroid. It's important to note that this function returns all the columns present in the provided `gpd.GeoDataFrame` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhgis.watershed_properties(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For added convenience, we can also retrieve the same results in the form of an `xarray.Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhgis.watershed_properties(\n",
    "    gdf[[\"Station\", \"geometry\"]], unique_id=\"Station\", output_format=\"xarray\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Land-use classification\n",
    "Land use classification is powered by the Planetary Computer's STAC catalog. It uses the `10m Annual Land Use Land Cover` dataset by default (\"io-lulc-9-class\"), but other collections can be specified by using the collection argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = xhgis.land_use_classification(gdf, unique_id=\"Station\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = xhgis.land_use_plot(gdf, unique_id=\"Station\", idx=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Climate indicators\n",
    "The step of extracting climatic indicators is the most complex. Indeed, to accomplish this, access to a weather dataset for the various watersheds within our `gdf` object is required. Fortunately, `xdatasets` precisely facilitates such operations. Indeed, `xdatasets` allows extracting from a gridded dataset all the pixels contained within a watershed while respecting the weighting of the watershed intersecting each pixel.Subsequently, the function `get_yearly_op`, built upon the `xclim` library, offers impressive flexibility in defining indicators tailored to the user's needs.\n",
    "\n",
    "To initiate the process, we employ ERA5-Land reanalysis data spanning the period from 1981 to 2010 as our climatological dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"era5_land_reanalysis\": {\"variables\": [\"t2m\", \"tp\", \"sd\"]},\n",
    "}\n",
    "space = {\n",
    "    \"clip\": \"polygon\",  # bbox, point or polygon\n",
    "    \"averaging\": True,\n",
    "    \"geometry\": gdf,  # 3 polygons\n",
    "    \"unique_id\": \"Station\",\n",
    "}\n",
    "time = {\n",
    "    \"start\": \"1981-01-01\",\n",
    "    \"end\": \"2010-12-31\",\n",
    "    \"timezone\": \"America/Montreal\",\n",
    "}\n",
    "\n",
    "ds = xd.Query(datasets=datasets, space=space, time=time).data.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the next few steps use [xclim](https://xclim.readthedocs.io/en/stable/index.html) under the hood, the dataset is required to be [CF-compliant](http://cfconventions.org/cf-conventions/cf-conventions.html). At a minimum, the `xarray.DataArray` used must follow these principles:\n",
    "\n",
    "- The dataset needs a time dimension, usually at a daily frequency with no missing timesteps (NaNs are supported). If your data differs from that, you'll need to be extra careful on the results provided.\n",
    "- If there is a spatial dimension, such as \"``Station``\" in the example below, it needs an attribute ``cf_role`` with ``timeseries_id`` as its value.\n",
    "- The variable will at the very least need a ``units`` attribute, although other attributes such as ``long_name`` and ``cell_methods`` are also expected by `xclim` and warnings will be generated if they are missing.\n",
    "- While this is not necessary for get_yearly_op, variable names should be one of those supported here for maximum compatibility.\n",
    "\n",
    "The following code adds the missing attributes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.rename({\"t2m\": \"tas\", \"tp\": \"pr\", \"sd\": \"snd\"})\n",
    "ds[\"tas\"] = xclim.core.units.convert_units_to(\n",
    "    ds[\"tas\"], \"degC\"\n",
    ")  # Convert from degK to degC\n",
    "ds[\"tas\"].attrs.update({\"cell_methods\": \"time: mean\"})\n",
    "\n",
    "ds[\"pr\"].attrs.update({\"units\": \"m d-1\", \"cell_methods\": \"time: mean within days\"})\n",
    "ds[\"pr\"] = xclim.core.units.convert_units_to(\n",
    "    ds[\"pr\"], \"mm d-1\"\n",
    ")  # Convert from m/d to mm/d\n",
    "\n",
    "ds[\"snd\"].attrs.update({\"units\": \"m\", \"cell_methods\": \"time: mean within days\"})\n",
    "ds[\"snd\"] = xclim.core.units.convert_units_to(ds[\"snd\"], \"mm\")  # Convert from m to mm\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second step, we can define seasons using indexers that are compatible with ``xclim.core.calendar.select_time``. There are currently four accepted types of indexers:\n",
    "\n",
    "- `month`, followed by a sequence of month numbers.\n",
    "\n",
    "- `season`, followed by one or more of `‘DJF’`, `‘MAM’`, `‘JJA’`, and `‘SON’`.\n",
    "\n",
    "- `doy_bounds`, followed by a sequence representing the inclusive bounds of the period to be considered (`'start'`, `'end'`).\n",
    "\n",
    "- `date_bounds`, which is the same as above, but using a month-day (`'%m-%d'`) format.\n",
    "\n",
    "Following this, we specify the operations we intend to calculate for each variable. The supported operations include `\"max\"`, `\"min\"`, `\"mean\"`, and `\"sum\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeargs = {\n",
    "    \"01\": {\"month\": [1]},\n",
    "    \"02\": {\"month\": [2]},\n",
    "    \"03\": {\"month\": [3]},\n",
    "    \"04\": {\"month\": [4]},\n",
    "    \"05\": {\"month\": [5]},\n",
    "    \"06\": {\"month\": [6]},\n",
    "    \"07\": {\"month\": [7]},\n",
    "    \"08\": {\"month\": [8]},\n",
    "    \"09\": {\"month\": [9]},\n",
    "    \"10\": {\"month\": [10]},\n",
    "    \"11\": {\"month\": [11]},\n",
    "    \"12\": {\"month\": [12]},\n",
    "    \"spring\": {\"date_bounds\": [\"02-11\", \"06-19\"]},\n",
    "    \"summer_fall\": {\"date_bounds\": [\"06-20\", \"11-19\"]},\n",
    "    \"year\": {\"date_bounds\": [\"01-01\", \"12-31\"]},\n",
    "}\n",
    "\n",
    "operations = {\n",
    "    \"tas\": [\"max\", \"mean\", \"min\"],\n",
    "    \"pr\": [\"sum\"],\n",
    "    \"snd\": [\"mean\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination of `timeargs` and `operations` through the Cartesian product yields a rapid generation of an extensive array of climate indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_climatology = xr.merge(\n",
    "    [\n",
    "        get_yearly_op(ds, input_var=variable, op=op, timeargs=timeargs)\n",
    "        for (variable, ops) in operations.items()\n",
    "        for op in ops\n",
    "    ]\n",
    ")\n",
    "ds_climatology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same data can also be visualized as a `pd.DataFrame` as well : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 100)\n",
    "ds_climatology.mean(\"time\").to_dataframe().T"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e28391989cdb8b31df72dd917935faad186df3329a743c813090fc6af977a1ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
