{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Hydrological modelling - Raven\n",
    "\n",
    "`xHydro` provides a collection of functions designed to facilitate hydrological modelling, focusing on two key models: [HYDROTEL](https://github.com/INRS-Modelisation-hydrologique/hydrotel) and a suite of models emulated by the [Raven Hydrological Framework](https://raven.uwaterloo.ca/). It is important to note that Raven already possesses an extensive Python library, [RavenPy](https://github.com/CSHS-CWRA/RavenPy), which enables users to build, calibrate, and execute models. `xHydro` wraps some of these functions to support multi-model assessments with HYDROTEL, though users seeking advanced functionalities may prefer to use `RavenPy` directly. \n",
    "\n",
    "The primary contribution of `xHydro` to hydrological modelling is thus its support for HYDROTEL, a model that previously lacked a dedicated Python library. This Notebook covers `RavenPy` models, but a similar notebook for `HYDROTEL` is available [here](hydrological_modelling_hydrotel.ipynb).\n",
    "\n",
    "## Basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xhydro as xh\n",
    "import xhydro.modelling as xhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "editable": true,
    "nbsphinx": "hidden",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Workaround for determining the notebook folder within a running notebook\n",
    "# This cell is not visible when the documentation is built.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "try:\n",
    "    from _finder import _find_current_folder\n",
    "\n",
    "    notebook_folder = _find_current_folder()\n",
    "except ImportError:\n",
    "    from pathlib import Path\n",
    "\n",
    "    notebook_folder = Path().cwd()\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "The `xHydro` modelling framework is based on a `model_config` dictionary, which is meant to contain all necessary information to execute a given hydrological model. For example, depending on the model, it can store meteorological datasets directly, paths to datasets (netCDF files or other), csv configuration files, parameters, and basically anything that is required to configure and execute an hydrological model.\n",
    "\n",
    "The list of required inputs for the dictionary can be obtained one of two ways. The first is to look at the hydrological model's class, such as `xhydro.modelling.RavenpyModel`. The second is to use the `xh.modelling.get_hydrological_model_inputs` function to get a list of the required keys for a given model, as well as the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(xhm.get_hydrological_model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xhydro as xh\n",
    "import xhydro.modelling as xhm\n",
    "\n",
    "# This function can be called to get a list of the keys for a given model, as well as its documentation.\n",
    "inputs, docs = xhm.get_hydrological_model_inputs(\"GR4JCN\", required_only=False)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "HYDROTEL and Raven vary in terms of required inputs and available functions, but an effort will be made to standardize the outputs as much as possible. Currently, all models include the following three functions:\n",
    "\n",
    "- `.run()`: Executes the model, reformats the outputs to be compatible with analysis tools in `xHydro`, and returns the simulated streamflow as a `xarray.Dataset`.\n",
    "  - The streamflow variable will be named `q` and will have units of `m3 s-1`.\n",
    "  - For 1D data (such as hydrometric stations), the corresponding dimension in the dataset will be identified by the `cf_role: timeseries_id` attribute.\n",
    "  \n",
    "- `.get_inputs()`: Retrieves the meteorological inputs used by the model.\n",
    "\n",
    "- `.get_streamflow()`: Retrieves the simulated streamflow output from the model.\n",
    "\n",
    "## Initializing and running a calibrated model\n",
    "Raven requires several `.rv*` files to control various aspects such as meteorological inputs, watershed characteristics, and more. Currently, `RavenPy` provides no straightforward way to open and modify these files. For instance, changing simulation dates or meteorological data directly through the files is not yet supported. \n",
    "\n",
    "Until this feature is added, all relevant information must be provided to `RavenPy` via the `model_config` dictionary in order to successfully run the model. For examples on how to obtain many of the required inputs, such as the watershed characteristics and meteorological data, consult the [GIS](gis.ipynb) and [Use Case Example](use_case.ipynb) notebooks. Therefore, this notebook will utilize a test dataset. All RavenPy models available currently in `xHydro` are lumped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import xclim\n",
    "\n",
    "from xhydro.testing.helpers import (  # In-house function to get data from the xhydro-testdata repo\n",
    "    deveraux,\n",
    ")\n",
    "\n",
    "D = deveraux()\n",
    "\n",
    "meteo_file = D.fetch(\"ravenpy/ERA5_Riviere_Rouge_global.nc\")\n",
    "ds = xr.open_dataset(meteo_file)\n",
    "ds = ds.rename({\"tmin\": \"tasmin\", \"tmax\": \"tasmax\"})\n",
    "\n",
    "ds.to_netcdf(notebook_folder / \"_data\" / \"meteo_hmr.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"model_name\": \"GR4JCN\",\n",
    "    \"parameters\": [\n",
    "        0.529,\n",
    "        -3.396,\n",
    "        407.29,\n",
    "        1.072,\n",
    "        16.9,\n",
    "        0.947,\n",
    "    ],  # GR4JCN has 6 parameters, others might have more\n",
    "    \"drainage_area\": 500,\n",
    "    \"elevation\": 120,\n",
    "    \"latitude\": 45.5,\n",
    "    \"longitude\": -71.8,\n",
    "    \"start_date\": \"1990-01-01\",\n",
    "    \"end_date\": \"1991-12-31\",\n",
    "    \"meteo_file\": notebook_folder / \"_data\" / \"meteo_hmr.nc\",\n",
    "    \"data_type\": [\"TEMP_MAX\", \"TEMP_MIN\", \"PRECIP\"],\n",
    "    \"alt_names_meteo\": {\"TEMP_MIN\": \"tasmin\", \"TEMP_MAX\": \"tasmax\", \"PRECIP\": \"pr\"},\n",
    "    \"meteo_station_properties\": {\n",
    "        \"ALL\": {\"elevation\": 500, \"latitude\": 45.5, \"longitude\": -71.8}\n",
    "    },\n",
    "    \"rain_snow_fraction\": \"RAINSNOW_DINGMAN\",\n",
    "    \"evaporation\": \"PET_HARGREAVES_1985\",\n",
    "    \"global_parameter\": {\"AVG_ANNUAL_SNOW\": 100.00},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "With `model_config` on hand, an instance of the hydrological model can be initialized using `xhydro.modelling.hydrological_model` or the `xhydro.modelling.RavenpyModel` class directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = xhm.hydrological_model(model_config)\n",
    "ht"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Validating the Meteorological Data\n",
    "\n",
    "Before executing hydrological models, a few basic checks will be performed automatically. However, users may want to conduct more advanced health checks on the meteorological inputs (e.g., identifying unrealistic values). This can be done using `xhydro.utils.health_checks`. For the full list of available checks, refer to [the 'xscen' documentation](https://xscen.readthedocs.io/en/latest/notebooks/3_diagnostics.html#Health-checks).\n",
    "\n",
    "We can use `.get_inputs()` to automatically retrieve the meteorological data. In this example, we'll ensure there are no abnormal meteorological values or sequences of values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_checks = {\n",
    "    \"raise_on\": [],  # If an entry is not here, it will warn the user instead of raising an exception.\n",
    "    \"flags\": {\n",
    "        \"pr\": {  # You can have specific flags per variable.\n",
    "            \"negative_accumulation_values\": {},\n",
    "            \"very_large_precipitation_events\": {},\n",
    "            \"outside_n_standard_deviations_of_climatology\": {\"n\": 5},\n",
    "            \"values_repeating_for_n_or_more_days\": {\"n\": 5},\n",
    "        },\n",
    "        \"tasmax\": {\n",
    "            \"tasmax_below_tasmin\": {},\n",
    "            \"temperature_extremely_low\": {},\n",
    "            \"temperature_extremely_high\": {},\n",
    "            \"outside_n_standard_deviations_of_climatology\": {\"n\": 5},\n",
    "            \"values_repeating_for_n_or_more_days\": {\"n\": 5},\n",
    "        },\n",
    "        \"tasmin\": {\n",
    "            \"temperature_extremely_low\": {},\n",
    "            \"temperature_extremely_high\": {},\n",
    "            \"outside_n_standard_deviations_of_climatology\": {\"n\": 5},\n",
    "            \"values_repeating_for_n_or_more_days\": {\"n\": 5},\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xclim.core.units import amount2rate\n",
    "\n",
    "ds_in = ht.get_inputs()\n",
    "ds_in[\"pr\"] = amount2rate(ds_in[\"pr\"])  # Precipitation in xclim needs to be a flux.\n",
    "\n",
    "xh.utils.health_checks(ds_in, **health_checks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Executing the Model\n",
    "\n",
    "A few basic checks are performed when the `.run()` function is called, before executing the model itself. For `RavenPy`, the following checks are made:\n",
    "\n",
    "- The model name is valid: [\"Blended\", \"GR4JCN\", \"HBVEC\", \"HMETS\", \"HYPR\", \"Mohyse\", \"SACSMA\"]\n",
    "\n",
    "Only if these checks pass will the function proceed to execute the model. Note that Raven itself will perform a series of checkups, which is why they are kept at a minimum in `xHydro`.\n",
    "\n",
    "Once the model is executed, `xHydro` will automatically reformat the NetCDF file to bring it closer to CF conventions, ensuring compatibility with other `xHydro` modules. Note that, at this time, this reformatting only supports the outgoing streamflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out = ht.run()\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht.get_streamflow()[\"q\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Model Calibration\n",
    "\n",
    "When building a model from scratch, a calibration step is necessary to find the optimal set of parameters. Model calibration involves a loop of several iterations, where: model parameters are selected, the model is run, and the results are compared to observed data. In `xHydro`, the calibration function utilizes `SPOTPY` to carry out the optimization process.\n",
    "\n",
    "The calibration function still uses the `model_config` dictionary created earlier, but now within the `xh.modelling.perform_calibration` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(xh.modelling.perform_calibration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "We can prepare the additional arguments required by the calibration function. A good calibration process should always exclude some data from the computation of the objective function to ensure a validation period. This can be achieved using the `mask` argument, which uses an array of 0 and 1. \n",
    "\n",
    "This example will only use 10 evaluations to cut on computing time, but a real calibration should rely on at least 500 iterations with simple models such as GR4JCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs_file = D.fetch(\"ravenpy/Debit_Riviere_Rouge.nc\")\n",
    "ds_obs = xr.open_dataset(qobs_file)\n",
    "\n",
    "# Reformat the data\n",
    "ds_obs = ds_obs.rename({\"qobs\": \"q\"}).sel(time=slice(\"1990\", \"1991\"))\n",
    "\n",
    "# Create the mask\n",
    "mask = xr.where(ds_obs.time.dt.year.isin([1990]), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter bounds for GR4JCN\n",
    "bounds_low = [0.01, -15.0, 10.0, 0.0, 1.0, 0.0]\n",
    "bounds_high = [2.5, 10.0, 700.0, 7.0, 30.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the calibration\n",
    "best_parameters, best_simulation, best_objfun = xhm.perform_calibration(\n",
    "    model_config,\n",
    "    obj_func=\"kge\",\n",
    "    bounds_low=bounds_low,\n",
    "    bounds_high=bounds_high,\n",
    "    qobs=ds_obs,\n",
    "    evaluations=10,\n",
    "    algorithm=\"DDS\",\n",
    "    mask=mask,\n",
    "    sampler_kwargs={\"trials\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first output corresponds to the best set of parameters\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second output corresponds to the timeseries for the best set of parameters\n",
    "best_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second output is the value of the objective function for the best set of parameters\n",
    "best_objfun"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
