{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Hydrological modelling - Raven (distributed)\n",
    "\n",
    "`xHydro` provides a collection of functions designed to facilitate hydrological modelling, focusing on two key models: [HYDROTEL](https://github.com/INRS-Modelisation-hydrologique/hydrotel) and a suite of models emulated by the [Raven Hydrological Framework](https://raven.uwaterloo.ca/). It is important to note that Raven already possesses an extensive Python library, [RavenPy](https://github.com/CSHS-CWRA/RavenPy), which enables users to build, calibrate, and execute models. `xHydro` wraps some of these functions to support multi-model assessments with HYDROTEL, though users seeking advanced functionalities may prefer to use `RavenPy` directly. \n",
    "\n",
    "The primary contribution of `xHydro` to hydrological modelling is thus its support for HYDROTEL, a model that previously lacked a dedicated Python library. This Notebook covers `RavenPy` models, but a similar notebook for `HYDROTEL` is available [here](hydrological_modelling_hydrotel.ipynb).\n",
    "\n",
    "## Basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "import xhydro as xh\n",
    "import xhydro.modelling as xhm\n",
    "\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "editable": true,
    "nbsphinx": "hidden",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Workaround for determining the notebook folder within a running notebook\n",
    "# This cell is not visible when the documentation is built.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "try:\n",
    "    from _finder import _find_current_folder\n",
    "\n",
    "    notebook_folder = _find_current_folder()\n",
    "except ImportError:\n",
    "    from pathlib import Path\n",
    "\n",
    "    notebook_folder = Path().cwd()\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "The `xHydro` modelling framework is based on a `model_config` dictionary, which is meant to contain all necessary information to execute a given hydrological model. For example, depending on the model, it can store meteorological datasets directly, paths to datasets (netCDF files or other), csv configuration files, parameters, and basically anything that is required to configure and execute an hydrological model.\n",
    "\n",
    "The list of required inputs for the dictionary can be obtained one of two ways. The first is to look at the hydrological model's class, such as `xhydro.modelling.RavenpyModel`. The second is to use the `xh.modelling.get_hydrological_model_inputs` function to get a list of the required keys for a given model, as well as the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(xhm.get_hydrological_model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function can be called to get a list of the keys for a given model, as well as its documentation.\n",
    "inputs, docs = xhm.get_hydrological_model_inputs(\"HBVEC\", required_only=False)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "HYDROTEL and Raven vary in terms of required inputs and available functions, but an effort will be made to standardize the outputs as much as possible. Currently, all models include the following three functions:\n",
    "\n",
    "- `.run()`: Executes the model, reformats the outputs to be compatible with analysis tools in `xHydro`, and returns the simulated streamflow as a `xarray.Dataset`.\n",
    "  - The streamflow variable will be named `q` and will have units of `m3 s-1`.\n",
    "  - For 1D data (such as hydrometric stations), the corresponding dimension in the dataset will be identified by the `cf_role: timeseries_id` attribute.\n",
    "  \n",
    "- `.get_inputs()`: Retrieves the meteorological inputs used by the model.\n",
    "\n",
    "- `.get_streamflow()`: Retrieves the simulated streamflow output from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Initializing and running a calibrated model\n",
    "Raven requires several `.rv*` files to control various aspects such as meteorological inputs, watershed characteristics, and more. Currently, `RavenPy` provides no straightforward way to open and modify these files. For instance, changing simulation dates or meteorological data directly through the files is not yet supported. Until this feature is added, all relevant information must be provided to `RavenPy` via the `model_config` dictionary in order to successfully run the model. \n",
    "\n",
    "If the project directory already exists and contains data, `xHydro` will prepare the model for execution without overwriting existing `.rv*` filesâ€”unless the `overwrite` argument is explicitly set to `True`. To force overwriting of these files, you can thus either:\n",
    "\n",
    "- Set `overwrite=True` in the `model_config` when instantiating the model\n",
    "- Use the `.create_rv(*args, overwrite=True, **kwargs)` method on the instantiated model. Note that if using that option, all necessary arguments need to be provided again.\n",
    "\n",
    "This Notebook will focus on distributed RavenPy models. For lumped models, refer to the [Raven lumped modelling notebook](hydrological_modelling_raven.ipynb).\n",
    "\n",
    "### Formatting HRU Data for distributed models\n",
    "\n",
    "Raven relies on Hydrological Response Units (HRUs) for its hydrological simulations. Distributed models require a long list of HRU attributes, which is not yet fully supported by `xHydro`. Users are encouraged to consult the [BasinMaker documentation](https://hydrology.uwaterloo.ca/basinmaker/) for a complete list of HRU attributes, and specifically the 'data specification file' available on their homepage. For distributed modelling, `xHydro` calls upon the `BasinMakerExtractor` class of `RavenPy` to extract HRU data from a shapefile, so users must ensure that their shapefile is formatted correctly.\n",
    "\n",
    "Additionally, while BasinMaker will produce attributes such as `Landuse_ID`, these will not be passed on to the `RavenPy` model. Instead, the HRU should contain relevant land use attributes that can be directly mapped to the hydrological model. For example, for the HBV-EC model, which is currently the only distributed model available in `Raven`, the following attributes are required: `LAND_USE_C`, `VEG_C`, and `SOIL_PROF`, which represent land use, vegetation, and soil profile respectively.\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>INFO</b>\n",
    "\n",
    "By default, HBV-EC as defined in `RavenPy` only understands a unique `LAND_USE_C` (`LU_ALL`), `VEG_C` (`VEG_ALL`), and `SOIL_PROF` (`DEFAULT_P`). If you want to use different classes, you will need to modify the `model_config` dictionary to include the relevant keys. There is currently no good documentation on how to do this, but you can refer to the class definition of the `HBVEC` model in `ravenpy.config.emulators.hbvec.py`.\n",
    "\n",
    "As an example, new vegetation classes can be added by modifying the `VegetationClasses` and `VegetationParameterList` keys with new entries detailing all the vegetation classes and their parameters. The same applies to land use and soil profile classes.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = gpd.read_file(\n",
    "    Path(notebook_folder).parents[2]\n",
    "    / \"xhydro-testdata\"\n",
    "    / \"data\"\n",
    "    / \"ravenpy\"\n",
    "    / \"hru_subset.shp\"\n",
    ")\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "df.plot(column=\"SubId\", ax=ax[0])\n",
    "ax[0].set_title(\"Subbasins\")\n",
    "df.plot(\n",
    "    column=\"LAND_USE_C\",\n",
    "    ax=ax[1],\n",
    "    legend=True,\n",
    "    legend_kwds={\"bbox_to_anchor\": (1.05, 1), \"loc\": \"upper left\"},\n",
    ")\n",
    "ax[1].set_title(\"Land Use\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep this example simple, and until cleaner methods are incorporated in xHydro, we will revert to the default HBVEC model configuration.\n",
    "# This is not recommended for real applications, as you will likely want to modify the model configuration to suit your needs.\n",
    "df.loc[:, \"LAND_USE_C\"] = \"LU_ALL\"\n",
    "df.loc[:, \"VEG_C\"] = \"VEG_ALL\"\n",
    "df.loc[:, \"SOIL_PROF\"] = \"DEFAULT_P\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Formatting Meteorological Data\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>INFO</b>\n",
    "\n",
    "If using multiple meteorological stations, it is recommended to add the `Interpolation` argument to `model_config` or the `RavenpyModel` call to control the interpolation algorithm. Raven uses the nearest neighbour method by default, but other options are available:\n",
    "\n",
    "- `INTERP_NEAREST_NEIGHBOR` (default) â€” Nearest neighbor (Voronoi) method  \n",
    "- `INTERP_INVERSE_DISTANCE` â€” Inverse distance weighting  \n",
    "- `INTERP_INVERSE_DISTANCE_ELEVATION` â€” Inverse distance weighting with consideration of elevation  \n",
    "- `INTERP_AVERAGE_ALL` â€” Averages all specified gauge readings  \n",
    "- `INTERP_FROM_FILE [filename]` â€” Weights for each gauge at each HRU are specified in an external file.  This method should work via `xHydro`, but it has not been fully tested.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>INFO</b>\n",
    "\n",
    "When using gridded meteorological data, `xHydro` uses functions from `RavenPy` to compute weights for each grid cell based on the HRU's geometry.  \n",
    "Ensure that the domain of the grid completely covers the watershed.\n",
    "\n",
    "</div>\n",
    "\n",
    "The acquisition of raw meteorological data is covered in the [GIS notebook](gis.ipynb) and [Use Case Example](use_case.ipynb) notebooks. Therefore, this notebook will use a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pooch\n",
    "import xarray as xr\n",
    "\n",
    "from xhydro.testing.helpers import (  # In-house function to get data from the xhydro-testdata repo\n",
    "    deveraux,\n",
    ")\n",
    "\n",
    "D = deveraux()\n",
    "\n",
    "ds = xr.open_zarr(\n",
    "    Path(\n",
    "        D.fetch(\n",
    "            \"pmp/CMIP.CCCma.CanESM5.historical.r1i1p1f1.day.gn.zarr.zip\",\n",
    "            pooch.Unzip(),\n",
    "        )[0]\n",
    "    ).parents[0]\n",
    ")\n",
    "ds_fx = xr.open_zarr(\n",
    "    Path(\n",
    "        D.fetch(\n",
    "            \"pmp/CMIP.CCCma.CanESM5.historical.r1i1p1f1.fx.gn.zarr.zip\",\n",
    "            pooch.Unzip(),\n",
    "        )[0]\n",
    "    ).parents[0]\n",
    ")\n",
    "\n",
    "ds[\"orog\"] = ds_fx[\"orog\"]\n",
    "ds = ds.drop_vars([\"height\"])\n",
    "ds[\"pr\"].attrs = {\"units\": \"mm\", \"long_name\": \"precipitation\"}\n",
    "ds = ds[[\"pr\", \"tas\", \"orog\"]]\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Every hydrological model has different requirements when it comes to their input data. In this example, the data has multiple issues that would be not compatible with the requirements for Raven. For reference on default units expected by Raven, consult [this link](https://ravenpy.readthedocs.io/en/latest/_modules/ravenpy/config/defaults.html#).\n",
    "\n",
    "The function `xh.modelling.format_input` can be used to reformat CF-compliant datasets for use in hydrological models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(xh.modelling.format_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use the 'save_as' argument to save the new file(s) in your project folder.\n",
    "ds_reformatted, config = xh.modelling.format_input(\n",
    "    ds,\n",
    "    \"HBVEC\",\n",
    "    save_as=notebook_folder / \"_data\" / \"meteo_hmr.nc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "While RavenPy does not require a configuration file to accompany the meteorological file, many information must be given to `model_config` to properly instantiate the model. The second output of `format_input` will return the \"meteo_file\", \"data_type\", \"alt_names_meteo\", and \"meteo_station_properties\" entries based on the provided file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_reformatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_copy = config.copy()\n",
    "config_copy[\"meteo_file\"] = \"/path/to/your/save_as/argument.nc\"\n",
    "config_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Initializing the Model\n",
    "\n",
    "The model can now be initialized using the information acquired so far.  \n",
    "Additional entries can be provided to the `model_config` dictionary, as long as they are supported by the emulated Raven model.\n",
    "\n",
    "In the example below, the `Interpolation` algorithm is customized, overriding the default values used by the HBVEC model.\n",
    "\n",
    "Refer to the [Raven documentation](https://raven.uwaterloo.ca/Downloads.html) for the most up-to-date information.  \n",
    "Model templates are currently listed in Appendix F, while the available options are described in various chapters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The HBVEC model has 21 parameters\n",
    "parameters = [\n",
    "    -0.15,\n",
    "    3.5,\n",
    "    3.0,\n",
    "    0.07,\n",
    "    0.4,\n",
    "    0.8,\n",
    "    1,\n",
    "    4.0,\n",
    "    0.5,\n",
    "    0.1,\n",
    "    1,\n",
    "    5.0,\n",
    "    4.8,\n",
    "    0.1,\n",
    "    1.0,\n",
    "    22.0,\n",
    "    0.5,\n",
    "    0.1,\n",
    "    0.0,\n",
    "    1.0,\n",
    "    1.0,\n",
    "]\n",
    "\n",
    "model_config = {\n",
    "    \"model_name\": \"HBVEC\",\n",
    "    \"parameters\": parameters,\n",
    "    \"global_parameter\": {\n",
    "        \"AVG_ANNUAL_RUNOFF\": 597\n",
    "    },  # Distributed models require an average annual runoff value at each HRU\n",
    "    \"hru\": df,\n",
    "    \"start_date\": \"2010-01-02\",\n",
    "    \"end_date\": \"2010-12-31\",\n",
    "    \"Interpolation\": \"INTERP_INVERSE_DISTANCE\",\n",
    "    **config,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "With `model_config` on hand, an instance of the hydrological model can be initialized using `xhydro.modelling.hydrological_model` or the `xhydro.modelling.RavenpyModel` class directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = xhm.hydrological_model(model_config)\n",
    "ht"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Validating the Meteorological Data\n",
    "\n",
    "Before executing hydrological models, a few basic checks will be performed automatically. However, users may want to conduct more advanced health checks on the meteorological inputs (e.g., identifying unrealistic values). This can be done using `xhydro.utils.health_checks`. For the full list of available checks, refer to [the 'xscen' documentation](https://xscen.readthedocs.io/en/latest/notebooks/3_diagnostics.html#Health-checks).\n",
    "\n",
    "We can use `.get_inputs()` to automatically retrieve the meteorological data. In this example, we'll ensure there are no abnormal meteorological values or sequences of values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_checks = {\n",
    "    \"raise_on\": [],  # If an entry is not here, it will warn the user instead of raising an exception.\n",
    "    \"flags\": {\n",
    "        \"pr\": {  # You can have specific flags per variable.\n",
    "            \"negative_accumulation_values\": {},\n",
    "            \"very_large_precipitation_events\": {},\n",
    "            \"outside_n_standard_deviations_of_climatology\": {\"n\": 5},\n",
    "            \"values_repeating_for_n_or_more_days\": {\"n\": 5},\n",
    "        },\n",
    "        \"tasmax\": {\n",
    "            \"tasmax_below_tasmin\": {},\n",
    "            \"temperature_extremely_low\": {},\n",
    "            \"temperature_extremely_high\": {},\n",
    "            \"outside_n_standard_deviations_of_climatology\": {\"n\": 5},\n",
    "            \"values_repeating_for_n_or_more_days\": {\"n\": 5},\n",
    "        },\n",
    "        \"tasmin\": {\n",
    "            \"temperature_extremely_low\": {},\n",
    "            \"temperature_extremely_high\": {},\n",
    "            \"outside_n_standard_deviations_of_climatology\": {\"n\": 5},\n",
    "            \"values_repeating_for_n_or_more_days\": {\"n\": 5},\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xclim.core.units import amount2rate\n",
    "\n",
    "with ht.get_inputs() as ds_in:\n",
    "    ds_in[\"pr\"] = amount2rate(ds_in[\"pr\"])  # Precipitation in xclim needs to be a flux.\n",
    "\n",
    "    xh.utils.health_checks(ds_in, **health_checks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Executing the Model\n",
    "\n",
    "A few basic checks are performed when the `.run()` function is called, before executing the model itself. Note that both RavenPy and Raven will perform a series of checkups, which is why they are kept at a minimum in `xHydro`.\n",
    "\n",
    "Once the model is executed, `xHydro` will automatically reformat the NetCDF file to bring it closer to CF conventions, ensuring compatibility with other `xHydro` modules. Note that, at this time, this reformatting only supports the outgoing streamflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out = ht.run()\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht.get_streamflow()[\"q\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Model Calibration\n",
    "\n",
    "When building a model from scratch, a calibration step is necessary to find the optimal set of parameters. Model calibration involves a loop of several iterations, where: model parameters are selected, the model is run, and the results are compared to observed data. In `xHydro`, the calibration function utilizes `SPOTPY` to carry out the optimization process.\n",
    "\n",
    "The calibration function still uses the `model_config` dictionary created earlier, but now within the `xh.modelling.perform_calibration` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(xh.modelling.perform_calibration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "We can prepare the additional arguments required by the calibration function. A good calibration process should always exclude some data from the computation of the objective function to ensure a validation period. This can be achieved using the `mask` argument, which uses an array of 0 and 1. \n",
    "\n",
    "This example will only use 10 evaluations to cut on computing time, but a real calibration should rely on at least 500 iterations with simple models such as GR4JCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "qobs_file = D.fetch(\"ravenpy/Debit_Riviere_Rouge.nc\")\n",
    "ds_obs = xr.open_dataset(qobs_file)\n",
    "\n",
    "# Reformat the data\n",
    "ds_obs = ds_obs.rename({\"qobs\": \"q\"}).sel(time=slice(\"1990\", \"1991\"))\n",
    "\n",
    "# Create the mask\n",
    "mask = xr.where(ds_obs.time.dt.year.isin([1990]), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter bounds for GR4JCN\n",
    "bounds_low = [0.01, -15.0, 10.0, 0.0, 1.0, 0.0]\n",
    "bounds_high = [2.5, 10.0, 700.0, 7.0, 30.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the calibration\n",
    "best_parameters, best_simulation, best_objfun = xhm.perform_calibration(\n",
    "    model_config,\n",
    "    obj_func=\"kge\",\n",
    "    bounds_low=bounds_low,\n",
    "    bounds_high=bounds_high,\n",
    "    qobs=ds_obs,\n",
    "    evaluations=10,\n",
    "    algorithm=\"DDS\",\n",
    "    mask=mask,\n",
    "    sampler_kwargs={\"trials\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first output corresponds to the best set of parameters\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second output corresponds to the timeseries for the best set of parameters\n",
    "best_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second output is the value of the objective function for the best set of parameters\n",
    "best_objfun"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
